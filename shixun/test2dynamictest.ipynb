{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#version2 方法拆分。正在改成version2，把json输出到txt看结果版本\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import pymysql\n",
    "import json\n",
    "import urllib.request\n",
    "from collections import OrderedDict\n",
    "#import httplib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ini_url = \"http://college.gaokao.com/spepoint/a1/y2012/p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '/User/ZJX/Desktop/text.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pagenum = 174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#写入到txt的老代码\n",
    "\n",
    "with open(\"/Users/ZJX/Desktop/text.txt\",'w',encoding='utf-8') as f:\n",
    "    for a in range(1,pagenum):\n",
    "        url = ini_url+str(a)\n",
    "        #print(url)\n",
    "        r=requests.get(url)\n",
    "        html=r.text\n",
    "        \n",
    "        List=[]\n",
    "        ret=[]\n",
    "        \n",
    "        s = etree.HTML(html)\n",
    "        \n",
    "        \n",
    "        \n",
    "        data = s.xpath('//*[@id=\"wrapper\"]/div[4]/table')\n",
    "        #获得整个表\n",
    "        \n",
    "        #获取实际输出的数据\n",
    "        for td in data:\n",
    "            content = td.xpath(\"./tr/td[position()<9]//text()\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #data = s.xpath('//*[@id=\"wrapper\"]/div[4]/table/tr/td[position()<9]//text()')\n",
    "        #获得整个表\n",
    "        \n",
    "        #存成dict转成json输出\n",
    "            for i in range(int((len(content)/8))):\n",
    "                major = content[(i-1)*8]\n",
    "                school = content[(i-1)*8+1]\n",
    "                av_score = content[(i-1)*8+2]\n",
    "                hi_score = content[(i-1)*8+3]\n",
    "                stu_province = content[(i-1)*8+4]\n",
    "                subject = content[(i-1)*8+5]\n",
    "                year = content[(i-1)*8+6]\n",
    "                pici = content[(i-1)*8+7]\n",
    "                \n",
    "                #List.append([school,stu_province,year,subject,major,pici,av_score,hi_score,''])\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                item = OrderedDict()\n",
    "                \n",
    "                item['school_name'] = school\n",
    "                item['province'] = stu_province\n",
    "                item['year'] = year\n",
    "                item['category'] = subject\n",
    "                item['major'] = major\n",
    "                item['batch'] = pici\n",
    "                item['avegrade'] = av_score\n",
    "                item['maxgrade'] = hi_score\n",
    "                item['mingrade'] = ''\n",
    "                \n",
    "                '''\n",
    "                item = {'school_name':school,'province':stu_province,'year':year,\\\n",
    "                       'category':subject,'major':major,'batch':pici,'avegrade':av_score,\\\n",
    "                        'maxgrade':hi_score,'mingrade':''\n",
    "                       }\n",
    "                       \n",
    "                '''\n",
    "                \n",
    "                #json_str = json.dumps(item,indent=4,ensure_ascii=False)\n",
    "                \n",
    "                ret.append(item)\n",
    "                \n",
    "                \n",
    "            json_str = json.dumps(ret,indent=4,ensure_ascii=False)    \n",
    "                \n",
    "            f.write(\"{}\\n\".format(json_str))\n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "            #data = td.xpath(\"./tr/td[position()<9]//text()\")\n",
    "            \n",
    "            \n",
    "            #f.write(\"{}\\n\".format(data))\n",
    "            \n",
    "            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-3d9abe92cb2d>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-3d9abe92cb2d>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    content = s.xpath(\"//*[@id=\"wrapper\"]/div[4]/table/tr/td[position()<9]//text()\")\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "#写入到txt的老代码\n",
    "\n",
    "with open(\"/Users/ZJX/Desktop/text.txt\",'w',encoding='utf-8') as f:\n",
    "    for a in range(1,pagenum):\n",
    "        url = ini_url+str(a)\n",
    "        #print(url)\n",
    "        r=requests.get(url)\n",
    "        html=r.text\n",
    "        \n",
    "        \n",
    "        \n",
    "        s = etree.HTML(html)\n",
    "        content = s.xpath('//*[@id=\"wrapper\"]/div[4]/table')\n",
    "        #获得整个表\n",
    "        \n",
    "        #获取实际输出的数据\n",
    "        for td in content:\n",
    "            data = td.xpath(\"./tr/td[position()<9]//text()\")\n",
    "            f.write(\"{}\\n\".format(data))\n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#下载并解析网页，提取数据形成list\n",
    "def getData():\n",
    "    try:\n",
    "        for a in range(1,pagenum):\n",
    "            url = ini_url+str(a)\n",
    "            r = requests.get()\n",
    "            html = r.text\n",
    "            \n",
    "            List=[]\n",
    "            ret=[]\n",
    "            \n",
    "            s=etree.HTML(html)\n",
    "            content = s.xpath(\"//*[@id=\"wrapper\"]/div[4]/table/tr/td[position()<9]//text()\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            for i in range((len(content)/8)):\n",
    "                major = content[(i-1)*8]\n",
    "                school = content[(i-1)*8+1]\n",
    "                av_score = content[(i-1)*8+2]\n",
    "                hi_score = content[(i-1)*8+3]\n",
    "                stu_province = content[(i-1)*8+4]\n",
    "                subject = content[(i-1)*8+5]\n",
    "                year = content[(i-1)*8+6]\n",
    "                pici = content[(i-1)*8+7]\n",
    "                \n",
    "                \n",
    "                item = {'school_name':school,'province':stu_province,'year':year,\\\n",
    "                       'category':subject,'major':major,'batch':pici,'avegrade':av_score,\\\n",
    "                        'maxgrade':hi_score,'mingrade':''\n",
    "                       }\n",
    "                ret.append(item)\n",
    "                \n",
    "                #List.append([major,school,av_score,hi_score,stu_province,subject,year,pici])\n",
    "            \n",
    "                \n",
    "            json_str = json.dumps(ret,indent=4,ensure_ascii=False)\n",
    "            \n",
    "            json = json.dumps({'cutoffList':json_str})\n",
    "            \n",
    "            request = requests.post(\"http://192.168.23.1:8080/addCutoff\",data=json.encode())\n",
    "            \n",
    "    except:\n",
    "        return \"error in getPageText\"\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
