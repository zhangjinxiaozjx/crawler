{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#version2 修改进行中版，正在改成version2;\n",
    "#已经改成version2，还未进行json传输测试，可以成功将json输出到txt，\n",
    "#具体运行见test2dynamictest文件\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import pymysql\n",
    "import json\n",
    "import urllib3.request\n",
    "from collections import OrderedDict\n",
    "#import httplib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ini_url = \"http://college.gaokao.com/spepoint/a1/y2012/p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '/User/ZJX/Desktop/text.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pagenum = 174\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(1,pagenum):\n",
    "    url = ini_url+str(a)\n",
    "    r = requests.get(url)\n",
    "    html = r.text\n",
    "            \n",
    "    #List=[]\n",
    "    ret=[]\n",
    "    ret.clear()\n",
    "            \n",
    "    s=etree.HTML(html)\n",
    "    content = s.xpath('//*[@id=\"wrapper\"]/div[4]/table/tr/td[position()<9]//text()')\n",
    "            \n",
    "    size =  int((len(content)/8))       \n",
    "            \n",
    "            \n",
    "    for i in range(size):\n",
    "        major = content[(i-1)*8]\n",
    "        school = content[(i-1)*8+1]\n",
    "        av_score = content[(i-1)*8+2]\n",
    "        hi_score = content[(i-1)*8+3]\n",
    "        stu_province = content[(i-1)*8+4]\n",
    "        subject = content[(i-1)*8+5]\n",
    "        year = content[(i-1)*8+6]\n",
    "        pici = content[(i-1)*8+7]\n",
    "          \n",
    "        item = OrderedDict()\n",
    "        \n",
    "        item['school_name'] = school\n",
    "        item['province'] = stu_province\n",
    "        item['year'] = year\n",
    "        item['category'] = subject\n",
    "        item['major'] = major\n",
    "        item['batch'] = pici\n",
    "        item['avegrade'] = av_score\n",
    "        item['maxgrade'] = hi_score\n",
    "        item['mingrade'] = ''\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        item = {'school_name':school,'province':stu_province,'year':year,\\\n",
    "                'category':subject,'major':major,'batch':pici,'avegrade':av_score,\\\n",
    "                'maxgrade':hi_score,'mingrade':''\n",
    "                }\n",
    "        '''       \n",
    "        \n",
    "        #下面两行，一条发一次json\n",
    "        #json_str = json.dumps(item,indent=4,ensure_ascii=False)\n",
    "        #request = requests.post(\"http://192.168.23.1:8080/saveCutoff\",data=json_str.encode())\n",
    "        #print(\"\\njson输出：   \",json_str)\n",
    "                \n",
    "        ret.append(item)\n",
    "        \n",
    "#print(ret)\n",
    " \n",
    "    data = {'cutoffModels':ret}\n",
    "    json_str = json.dumps(data,ensure_ascii=False)\n",
    "    \n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    request = requests.post(\"http://192.168.23.1:8080/addCutoff\", data=json_str.encode('utf-8'), headers=headers)\n",
    "\n",
    "    \n",
    "    \n",
    "#下面这行一页转一次json\n",
    "#json_str = json.dumps(ret,indent=4,ensure_ascii=False)\n",
    "#print(\"\\njson输出：   \",json_str)\n",
    "        \n",
    "        \n",
    "#json传送爬取的数据\n",
    "#value = urllib.parse.urlenconde(data).encode(encoding='UTF8')\n",
    "#headers = {'Content-Type':'application/json'}\n",
    "#request = urllib.request.Request(url='http://192.168.23.1:8080/addCutoff',headers=headers,data=json_str.encode())\n",
    "#response = urllib.request.urlopen(request)\n",
    "        \n",
    "        \n",
    "#锴哥打的包\n",
    "#json_str2 = json.dumps({'cutoffs':json_str})\n",
    "#发送锴哥打的包\n",
    "#request = requests.post(\"http://192.168.23.1:8080/addCutoff\",data=json_str2.encode())\n",
    "        \n",
    "#直接发，不打包，下面这行，一页发一次json\n",
    "#request = requests.post(\"http://192.168.23.1:8080/addCutoff\",data=json_str.encode())\n",
    "    \n",
    "     \n",
    "                \n",
    "        \n",
    "        \n",
    "#ret.append(item)\n",
    "                \n",
    "#List.append([major,school,av_score,hi_score,stu_province,subject,year,pici])\n",
    "        \n",
    "        \n",
    "        \n",
    "#json_str = json.dumps(ret,indent=4,ensure_ascii=False)\n",
    "            \n",
    "#json = json.dumps({'cutoffList':json_str})\n",
    "            \n",
    "#request = requests.post(\"http://192.168.23.1:8080/addCutoff\",data=json.encode())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\"/Users/ZJX/Desktop/tianjin.txt\",\\'w\\',encoding=\\'utf-8\\') as f:\\n    for a in range(1,pagenum):\\n        url = ini_url+str(a)\\n        #print(url)\\n        r=requests.get(url)\\n        html=r.text\\n        \\n        s = etree.HTML(html)\\n        content = s.xpath(\\'//*[@id=\"wrapper\"]/div[4]/table\\')\\n        #\\xe8\\x8e\\xb7\\xe5\\xbe\\x97\\xe6\\x95\\xb4\\xe4\\xb8\\xaa\\xe8\\xa1\\xa8\\n        \\n        #\\xe8\\x8e\\xb7\\xe5\\x8f\\x96\\xe5\\xae\\x9e\\xe9\\x99\\x85\\xe8\\xbe\\x93\\xe5\\x87\\xba\\xe7\\x9a\\x84\\xe6\\x95\\xb0\\xe6\\x8d\\xae\\n        for td in content:\\n            data = td.xpath(\"./tr/td[position()<9]//text()\")\\n            f.write(\"{}\\n\".format(data))\\n            \\n            \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "with open(\"/Users/ZJX/Desktop/tianjin.txt\",'w',encoding='utf-8') as f:\n",
    "    for a in range(1,pagenum):\n",
    "        url = ini_url+str(a)\n",
    "        #print(url)\n",
    "        r=requests.get(url)\n",
    "        html=r.text\n",
    "        \n",
    "        s = etree.HTML(html)\n",
    "        content = s.xpath('//*[@id=\"wrapper\"]/div[4]/table')\n",
    "        #获得整个表\n",
    "        \n",
    "        #获取实际输出的数据\n",
    "        for td in content:\n",
    "            data = td.xpath(\"./tr/td[position()<9]//text()\")\n",
    "            f.write(\"{}\\n\".format(data))\n",
    "            \n",
    "            \n",
    "'''        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#\\xe7\\x94\\xa8BeautifulSoup\\xe8\\xa7\\xa3\\xe6\\x9e\\x90\\nr=requests.get(url)\\nhtml=r.text\\n\\nsoup=BeautifulSoup(html,'lxml')\\nsoup.prettify()\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#用BeautifulSoup解析\n",
    "r=requests.get(url)\n",
    "html=r.text\n",
    "\n",
    "soup=BeautifulSoup(html,'lxml')\n",
    "soup.prettify()\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#\\xe4\\xbd\\xbf\\xe7\\x94\\xa8xpath\\xe8\\xa7\\xa3\\xe6\\x9e\\x90\\nr=requests.get(ini_url)\\nhtml=r.text\\ns = etree.HTML(html)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#使用xpath解析\n",
    "r=requests.get(ini_url)\n",
    "html=r.text\n",
    "s = etree.HTML(html)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['环境科学', '北京大学', '639', '646', '北京', '理科', '2012', '第一批', '心理学', '北京大学', '645', '659', '北京', '理科', '2012', '第一批', '考古学', '北京大学', '645', '666', '北京', '理科', '2012', '第一批', '地质学基地班', '北京大学', '647', '654', '北京', '理科', '2012', '第一批', '工程力学类', '北京大学', '649', '662', '北京', '理科', '2012', '第一批', '电子信息科学类', '北京大学', '653', '678', '北京', '理科', '2012', '第一批', '地球与空间科学', '北京大学', '655', '655', '北京', '理科', '2012', '第一批', '新闻传播学类', '北京大学', '655', '670', '北京', '理科', '2012', '第一批', '国际政治', '北京大学', '655', '668', '北京', '理科', '2012', '第一批', '英语', '北京大学', '656', '657', '北京', '理科', '2012', '第一批', '天文学', '北京大学', '658', '666', '北京', '理科', '2012', '第一批', '公共管理类', '北京大学', '659', '663', '北京', '理科', '2012', '第一批', '环境科学类', '北京大学', '659', '666', '北京', '理科', '2012', '第一批', '数学类', '北京大学', '663', '686', '北京', '理科', '2012', '第一批', '生物科学', '北京大学', '664', '691', '北京', '理科', '2012', '第一批', '法学', '北京大学', '664', '690', '北京', '理科', '2012', '第一批', '经济学类', '北京大学', '664', '683', '北京', '理科', '2012', '第一批', '中国语言文学类', '北京大学', '665', '678', '北京', '理科', '2012', '第一批', '化学类', '北京大学', '667', '677', '北京', '理科', '2012', '第一批', '工商管理类', '北京大学', '669', '689', '北京', '理科', '2012', '第一批', '物理学类', '北京大学', '670', '702', '北京', '理科', '2012', '第一批', '理科试验班类', '北京大学', '672', '688', '北京', '理科', '2012', '第一批', '信息管理与信息系统', '北京大学', '600', '600', '北京', '文科', '2012', '第一批', '社会学', '北京大学', '603', '607', '北京', '文科', '2012', '第一批', '公共管理类', '北京大学', '611', '616', '北京', '文科', '2012', '第一批']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "data = s.xpath('//*[@id=\"wrapper\"]/div[4]/table/tr/td[position()<9]//text()')\n",
    "print(data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
